---
title: "R wizardry course Week 3, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
proc.time()
```




# Week 3 content

3.1 How to create projects in R
3.2. Arithmetic operators
3.3 Subsetting data with predefined functions from base R and dplyr (package)
3.4 Calculations based on another column
3.5 Brief intro to graphs using R base plotting functions
3.6 Create and export a summary table
3.7 Selecting data based on another column
3.8 Finding data based on its value
3.9 Random numbers and selecting random data
3.10 Strings



## Before starting:
* Googling and solving R errors

* Reminder about office hours dinamyc: send your question in advance and show us you have searched the aswer by yourself. We're not being mean, this is simply the way how learning programming works...

* Mid term feedback

* Some examples of final projects from previous years

* Upload homework 1 to D2L.

* Disccuss homeworks solutions.

* During this lecture we'll build the dataset to be used during the plotting lectures. 



## 3.1 How to create projects in R

File > New Project. This can be linked to an existent folder or to a new one.


## 3.2 Arithmetic operators

```{r}
rm(list=ls(all=TRUE))

ints <- 1:50

?"%%"
help("%%")


```


To find "types" of numbers, %/% and %% are handy

```{r}

# %% returns the remainder
ints%%3

# %/% returns the quotient
ints%/%3

#Even numbers
ints%%2 == 0 # Logic

ints[ints%%2 == 0] # Numeric

#numbers divisible by 5 **OR** 6
ints[ints%%5 == 0 | ints%%6 == 0]

# Numbers that are not divisible by 4
ints[ints%%4 != 0]

```



Can also use brackets for more complicated selections

```{r}
ints[(ints%%5 == 0 | ints%%6 == 0) & ints <= 30]

ints[ints%%5 == 0 | (ints%%6 == 0 & ints <= 30)]
```


### Problem 1
Use logical operators to simultaneously find the odd numbers between -50 and 0 (inclusive) and the even numbers between 0 and 50 (inclusive)

```{r}

ints <- -50:50

ints[(ints <=0 & ints%%2 == 1) | (ints >=0 & ints%%2 == 0)]
```



##Extra: Loading sessions and rds objects from previous R sessions


Load the long-format "compounds" (tidy.compounds) dataset created during week 2 (the compressed file with the extension ".rds").

```{r}
#Before reading the format, ask where in the directory you're in:
getwd()

#If not in the course's folder, set properly the working directory:
setwd("/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 3")
getwd() #To make sure that the working directory was corectly set. Now, anything we save will go to the "2017. Day 3" folder.

#Let's see what's in this directory (or folder)
dir()

# Load "compounds.csv" dataset from week 2 folder. As the dataset was saved in the folder week 2 (not the current working directory, which is week 3), I'll read the file in by specifung the full path to the compounds.rds object:


#To read the RDS file
tidy.compounds <- read.csv("/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 3/compounds_stats.csv")

# Give it a shorter name
compounds <- tidy.compounds

View(compounds)

str(compounds)
```


We can also write and read text files into R (csv, txt, tsv, etc.). To write tidy.compounds as a comma separated value (csv):
```{r}

# After writting a file, consider commenting out that line
#write.csv(tidyCompounds, "/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 2/tidy_compounds.csv", row.names = FALSE)

#To read the csv file:
#compounds <- read.csv("/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 2/tidy_compounds.csv")
 

compounds <- tidy.compounds 
str(compounds)
compounds$compound
unique(compounds$compound)

```


## Subsetting data with predefined functions from base R and dplyr (package)
Can use subset() to split the data based on some logical argument contained within the dataset. For example, let's only look at data from the first half of the experiment (before day 200)

```{r}

#Option 1
earlyCompounds <- subset(compounds, compounds$day < 200); earlyCompounds


#Option 2

#install.packages("dplyr")
library(dplyr)
earlyCompounds2 <- compounds %>% filter(day < 200); earlyCompounds2

# alternatively,
earlyCompounds3 <- compounds %>% dplyr::filter((day < 200)); earlyCompounds3

unique(earlyCompounds$day); unique(earlyCompounds2$day); unique(earlyCompounds3$day)
```



## Missing data and NA's

NA represents an empty slot and are also produced when invalid math is attempted. In addition to TRUE and FALSE, NA is another type of logical variable

```{r}
class(NA)

as.numeric("a")
```


Unfortunately, we often have to deal with missing data so lets throw some in
```{r}
mean(compounds$methane)
head(compounds)

```

Having NA messes up a lot of functions
```{r}

median(compounds[ , "methane_umoles"])
mean(compounds[, 7])

```


Often there are built in ways to ignore them most common functions have a parameter such as na.rm, na.omit, na.exclude, etc...
```{r}
mean(compounds[,7], na.rm = TRUE) 
mean(compounds[,"methane_umoles"], na.rm=TRUE)
```

But we can use logic arguments to ignore NAs, e.g. is.na()
```{r}

a <- cbind(compounds[1:10, 7],
      !is.na(compounds[1:10,7])) #Column-bind Returns 1 (TRUE) or 0 (FALSE)

# Why are we getting 0 and 1 in column 2 if we were expecting logical (TRUE or FALSE) data?
# Becuase cbind() creates matrices by default!

data.frame(compounds[1:10, 7], 
           !is.na(compounds[1:10,7])) #data.frame Returns TRUE or FALSE

```


### Problem 2:
Subset the dataset tidy.compounds based on the variable "compound", selecting only the data corresponding to methane observations in benzene-amended incubations. Select only those observations that have actual numeric vaues (no NAs), then calculate the mean.

```{r}

# Select data that is NOT NA
data.frame(tidy.compounds[ , 1 == "benzene"],
           !is.na(tidy.compounds[ , 6]))

# Select data that IS NA
data.frame(tidy.compounds[ , 1 == "benzene"],
is.na(tidy.compounds[ , 6]))


# Let's add the rest of the code to select observations corresponding to benzene and that have no NAs in the methane values.

benzene_only <- tidy.compounds[tidy.compounds$compound == "benzene" &
                 !is.na(tidy.compounds[ , 6]), ]

# Get the mean of the methane for days
mean(benzene_only$methane_umoles)    

```




## 3.4 Calculations based on another column

```{r}
colnames(compounds)
head(compounds)
```


"tapply()" applys a function to one column based on the groups found in another column
```{r}
?tapply

# Mean of methane based on salinity or group factors
tapply(compounds$methane_umoles, compounds$salinity, FUN=mean, na.rm=TRUE)

tapply(compounds$methane_umoles, compounds$group, FUN=sd, na.rm=TRUE)

```



Aggregate is the general form, allowing you to group by more than one column.

```{r}

?aggregate

aggregate(compounds$methane_umoles, list(compounds$compound,compounds$group), mean)

#A disadvantage of "aggregate()" is that you have to rename the columns
aggregate(compounds$methane_umoles,
          list(compounds$day),
          mean)

aggregate(compounds$methane_umoles, 
          list(compounds$compound, 
               compounds$group), 
               #compounds$day),
          FUN = mean,
          na.rm=TRUE)

```


ALTERNATIVELY, this form keeps the names

```{r}
aggregate(methane_umoles ~ compound + group, 
          data=compounds, 
          FUN=mean, 
          na.rm=T)

```


A third way to use aggregate. Let's calculate the mean and standard deviation in the methane reads by day.

```{r}
head(compounds)

str(compounds)

# Don't add rm.na = TRUE to aggregate as it gives NaNs for mean and doesn't calculate sd. Its default is na.omit.
methane_mean_day <- aggregate(compounds$methane_umoles, 
                              by = list(compounds$compound,
                                        compounds$salinity,
                                        compounds$group,
                                        compounds$day),
                                        #compounds$staff),
                            FUN = mean)

head(methane_mean_day,20)



methane_sd_day <- aggregate(compounds$methane_umoles, 
                            by = list(compounds$compound,
                                      compounds$salinity,
                                      compounds$group,
                                      compounds$day),                                    
                                      #compounds$staff),
                            FUN = sd)

methane_sd_day

View(methane_sd_day)
```



### Problem 3

At this point there are two datasets that only differ in one column: one contains means and the other the standar deviations. Make a single dataset called "compouds_stats"" with no repeated varialbles out the two, and rename the columns as "compound", "salinity", "group", "day", "staff", "methane_mean", and "sd_methane".

```{r}

#The easiest will be extract the column from one dataset (e.g. methane_day_sd$x) and add it to the other dataset (e.g. methane_day_mean):
compounds_stats <- cbind(methane_mean_day, methane_sd_day$x)
head(compounds_stats, 20)

str(compounds_stats)

colnames(compounds_stats) <- c("compound", "salinity", "group", "day", #"staff",
                               "methane_mean", "methane_sd")
head(compounds_stats, 13)
View(compounds_stats)
```
#Write the compounds_stats

Adding a column of NEW DATA to an existing dataset

```{r}

compounds_stats$staff <- rep(c("Willy_Wonka","Chuck_Norris"), 
                             length(compounds_stats$day) / 2)

head(compounds)
# Alternatively could do that more robustly
compounds_stats$staff <- rep(c("Willy_Wonka","Chuck_Norris"),1000)[1:length(compounds_stats$day)]
head(compounds_stats)

compounds_stats$staff <- as.factor(compounds_stats$staff)

View(compounds_stats)

```


Let's say you wanted to quickly calculate your sample size for each combination of compound and group. How would we do that in such a way that R is not counting the NAs?

There are three ways:

```{r}

aggregate(compounds_stats,
          list(compounds_stats$compound,compounds_stats$group),
          function(x)(sum(!is.na(x))))

aggregate(compounds,
          list(compounds$compound,compounds$group),
          function(x)(length(x[!is.na(x)])))

```


## 3.5 Brief intro to graphs using R base plotting functions
Although during the course we won't use the basic R plotting that much as we'll focus on the ggplot2 package, it's good to understand the very basics.


```{r}

#read the compounds_stats saved file
compounds_stats <- read.csv("/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 3/compounds_stats.csv")

str(compounds_stats)

plot(methane_mean ~ day, data = compounds_stats)

plot(compounds_stats$day, compounds_stats$methane_mean)
```


Here is a variety of ways to plot box-and-whisker plots in R

```{r}
boxplot(methane_mean ~ group, 
        data = compounds_stats, 
        col="steelblue", 
        ylab="Median Methane Formation", 
        range=0, ylim=c(-20, 240))

boxplot(methane_mean ~ group, 
        data = compounds_stats, 
        col="steelblue", ylab="Median Methane Formation", 
        range=1, ylim=c(-20, 240))

boxplot(methane_mean ~ group, 
        data = compounds_stats, 
        col="steelblue", ylab="Median Methane Formation", 
        outline=FALSE, ylim=c(-20, 240), boxwex=0.25)

```


## 3.6 Create and export a summary table

```{r}
ag <- aggregate(methane_mean ~ day + compound + group, 
                data=compounds_stats, 
                FUN=median)

ag

head(compounds_stats)
```


The following is a function to check if the name you want to use for your new csv file does already exists in your computer. This will prevent you from overwritting an existent file by mistake:

```{r}

if(sum(dir() == "Methane medians.csv") > 0) {print("For fuck sakes!!!! Stop it! The file already exists")} else {print("You're good to go... Write it")} 

write.csv(ag, "Methane medians.csv", row.names = FALSE)

#As long as you have a file with the name "Methane medians.csv" in your set directory, you'll get the warning. If you delete the file from your folder, the warning won't show up anymore.

```


## 3.7 Selecting data based on another column

We have been selecting data based on itself. We can also select data based on other data.

We can find the odd letters
```{r}
?letters
letters[(1:26)%%2 == 1]
```

We can select the data collected on day 1
```{r}
compounds_stats[compounds_stats$day == 1, ]
```


We can select the data collected on day 1 and day 10
```{r}
compounds_stats[compounds_stats$day == 1 | compounds_stats$day == 10,]
```


We can select based on 2 or more data types
```{r}
compounds_stats[compounds_stats$day == 1 & compounds_stats$compound == "unamended", ]
```


We can store this subsetted data into a new variable
```{r}
subcompounds <- compounds_stats[compounds_stats$day == 1 & 
                                  compounds_stats$compound == "unamended", ]

subcompounds$methane_mean
subcompounds$methane_sd

```


## 3.8 Finding data based on its value


```{r}
?which

compounds_stats$day == 1

which(compounds_stats$day == 1) 
which(is.na(compounds_stats$day))

#Get the row number containing the highest methane read
which(compounds_stats$methane_mean == max(compounds_stats$methane_mean, na.rm = TRUE))

#Get the entire info of row containing the highest methane read
compounds_stats[which(compounds_stats$methane_mean == max(compounds_stats$methane_mean, 
                                                    na.rm = T)),]
```


## 3.9 Random numbers and selecting random data

```{r}
?runif
?rnorm
?rgamma
?rpois
?rnbinom
?rbinom
?sample

runif(10, min=0, max=1)
runif(10, 0, 1) < 0.4
rnorm(10, mean=1, sd=1)
sample(1:10, size=4)

#Set the seed to create reproducible simulations.
set.seed(1)
runif(10,0,10)

#compounds_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")

compounds_stats$methane_mean[runif(length(compounds_stats$methane_mean), 
                                   min=0, max=1) < 0.1] #Min and max are the lower and upper limits of the distribution


sample(compounds_stats$methane_sd, size=10, replace=TRUE)

```


## 3.10 Strings

```{r}
#rm(list=ls(all=TRUE))

#compounds_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")

?substring()
?strsplit()
?paste()
?sub()
?gsub()
?grep()
?sapply()
?match()
?unique
```

### 3.10.1 Logical operators on strings
```{r}

?as.integer
?c
?"["
?letters

int <- 1:20
int[int<10]
char <- letters
letters[letters < "f"]
words <- c("1","hello","hello2", "my", "name", "is", "computer")
words <= "hello3"
# R is smart (most of the time), for logical operators it ranks character sequences alpha-numerically

```


### 3.10.2 Combining strings
```{r}

?paste

#Use the paste function to combine multiple vectors of character data into a single string
paste("a", "b", "c")

#Can change the seperation using the sep parameter
paste("a", "b", "c", sep = "-")
paste("a", "b", "c", sep = "")

compounds_stats$new.col <- paste(compounds_stats$salinity, compounds_stats$group, sep="_")
head(compounds_stats)

# can combine multiple objects from a single vector into a single string
phrase <- c("Fish","Are","Friends")
nchar(phrase)
newphrase = paste(phrase,collapse=' '); newphrase
nchar(newphrase)

#Can combine any one-celled variable
paste(1,"1","&", "one")

#If you have multi-celled variables, you will create multiple strings
paste("replicate", 1:10, sep = ": ")
```


### 3.10.3 Seperating strings
```{r}

?substring
?nchar
?strsplit
?sub

#substring (aka substr) and strsplit can seperate strings

#substring grabs the characters between two points in the string
string <- paste(1,2,3,4,5,6,7,8,9, sep = "")
substring(string, first=1, last=3)
substr(string, start=1, stop=3)

substring(string,7,9)
substring(string,9,5)
substring(string,9,100) #The last element is "9"


#nchar tells you how long the string is
nchar(string)
substring(string, 5, nchar(string))

#strsplit seperates the string into fragments
#It makes breaks when it finds the string you want within the larger string
geno <- "TACAGATATCCGGA"
strsplit(geno, "TA")

#The string you are breaking on is not included in the output
getwd()
workingdir <- "/home/oscar/MEGAsync/R Wizardry/Materials 2018/Week 3"

workingdir <- getwd()

strsplit(workingdir, "/")

#strsplit puts its output inside of a list (since the arrays in the list can be of different sizes)
#We get pull the relevant vector/array out of a list using [[NUMBER]]
strsplit(workingdir, "/")[[1]]
strsplit(workingdir, "/")[[1]][4:8]


#We can use sapply if our list has multiple slots and each array is the same size
string <- c("G1:TACA", "G2:TTTA", "G3:ACCT"); string

sub(".*:", "", string) # Use any of the characters inside the quoatation marks as string separator
sub(":","HAPPY",string)

#The ".*X" syntax is a regular expression that is recognizable to perl and other languages. It is matching the X argument after any given string, in this case it is matching on the colon (:) and splitting the string and ignoring everything prior to the colon

sapply(strsplit(string, ":"), "[") # Get both sides

sapply(strsplit(string, ":"), "[", 2)


# Try a value of 1, and a value of 2 here
sapply(strsplit(string, ":"), "[", 1)

# Why does the sapply function work??? Because the command "[" is a command to R to extract information specific to lists and the function 'strsplit' creates an object formatted as a list

sapply(strsplit(string, ":"), "[", 1) 

```

### 3.10.4 Managing strings

```{r}

?"[["
?substr
?substring


read.table(text = string, sep = ":", as.is = TRUE)
read.table(text = string, sep = ":", as.is = TRUE)$V2

# substring(x, start, stop)
string; substring(string, 3)
string; substring(string, 4)
string; substring(string, 5)

## ^^ Try different values instead of 4, such as 3, 5, 1, etc.

tes <- c("1gene.GATTACA","2gene.GTCATTA","3gene.ATTCGAA")
dat <- c(5,3,2)
h <- data.frame(tes, dat)

# Other ways to get similar results as previously done
sapply(strsplit(as.character(h$tes), "\\."), "[")
sapply(strsplit(as.character(h$tes), "\\."), "[", 1)


# ^^ Try different values for 1 above

nx <- c(Abc = 123, pi = pi)
nx[1] ; nx["pi"] # keeps names, whereas "[[" does not:
nx[[1]] ; nx[["pi"]]
```



### 3.10.5 Matching strings

```{r}
?match
?grep

words
words <- c("1","hello","hello2", "my", "name", "is", "computer")
match("hello",words)
grep("hello",words)

match("me",words)
grep("me",words)

words[grep("me",words)]
```


### 3.10.6 Partial matches and regular expressions

```{r}
?sample
?letters
?grep
?grepl
?paste
?regexpr
?strsplit
?unlist
```



Let's create a fake sequence of genomic data, 100,000 bp long each of the 4 bp A, C, G, and T have equal probability of being represented we want to sample from the letters a, c, g, and t, with replacement

```{r}
set.seed(1)
genome <- sample(c("g","a","c","t"),size=1e4,replace=TRUE,prob=c(1/4,1/4,1/4,1/4))

unique(genome)
```

this gives us the individual vector positions of the genome for each bp
```{r}
genome[10] # this is the 10th bp of the genomic sequence
```


let's collapse this down into a single character vector
```{r}
geneseq <- paste(genome, collapse='')
```

let's say that we are interested in finding out where/if a specific sequence occurs the sequence of interest is GATTACA

```{r}
gene <- "gattaca"
```


We can use regular expressions to find out where among the single character vector that R first returns a positive hit for GATTACA

```{r}
x <- regexpr(gene, geneseq)
x
```


Let's verify that this is indeed the bp in the genome corresponding to that return
```{r}
genome[x[1]:(x[1]+6)]
```


Let's then split the genomic sequence up around GATTACA (i.e., split the genomic sequence up and remove GATTACA). For each positive hit on GATTACA, it will split split the vector
```{r}
y <- unlist(strsplit(geneseq,gene)) #Divides original sequence into two vectors, based on gattaca

length(y)-1 # This returns the number of matches for GATTACA in the genomic sequence

grepl(gene, geneseq) # is GATTACA in the original genomic sequence? TRUE/FALSE
```


does each remaining subsection of the genome contain GATTACA?
```{r}
grepl(gene,y) # this should return FALSE as we split the sequence on GATTACA's 
```


What if you were then interested in the pieces of the genome that contained an additional bp sequence of interest, such as AAACGGG?

```{r}
grep("aaacggg", y)
regexpr("aaacggg", y) # where does AAACGGG first occur?
```


Alternatively you could do this:
```{r}
nchar(geneseq)
nchar(y) 
genome <- genome[(x[1]+attr(x,"match.length")):length(genome)]
geneseq <- paste(genome,collapse='')
nchar(geneseq)
z <- regexpr(gene,geneseq)
genome[z[1]:(z[1]+attr(z,"match.length")-1)]
genome <- genome[(z[1]+attr(x,"match.length")):length(genome)]
geneseq <- paste(genome,collapse='')
nchar(geneseq)

#rinse and repeat to find all genomic locations that contain GATTACA bp sequence
```



END OF WEEK 3, 2018

