---
title: "R wizardry course Week 3, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
proc.time()
```




# Week 3 content

1.1 How to create projects in R
1.2. Arithmetic operators
1.3 Calculations based on another column
1.4 Brief intro to graphs using R base plotting functions
1.5 Create and export a summary table
1.6 Selecting data based on another column
1.7 Finding data based on its value
1.8 Random numbers and selecting random data
1.9 Strings



## Before starting:
* Googling and solving R errors
```{r , eval=FALSE}
x + 1 #The first thing to do is copy the error meesage into google. Pay especial attention to search results from pages like Stackoverflow, R-Bloggers, etc. Some google groups may also be helpful.

```


* Reminder about office hours dinamyc: send your question in advance and show us you have searched the aswer by yourself. We're not being mean, this is simply the way how learning programming works...

* Mid term feedback

* Some examples of final projects from previous years

* Upload homework 1 to D2L.

* During this lecture we'll build the dataset to be used during the plotting lectures.



## 1.2. Arithmetic operators

```{r}
rm(list=ls(all=TRUE))


?"%%"
#?%% # Error
help("%%")

```


To find "types" of numbers, %/% and %% are handy

```{r}

ints <- 1:50
ints

# %% returns the remainder
ints%%2

# %/% returns the quotient
ints %/% 3

#Even numbers
ints%%2 == 0 #Logic

ints[ints%%2 == 0] #Numeric answer

#numbers divisible by 5 or 6
ints[ints%%5 == 0 | ints%%6 == 0]


# Numbers that are not divisible by 4
ints[ints%%4 != 0 ]

```



Can also use brackets for more complicated selections

```{r}
ints[(ints%%5 == 0 | ints%%6 == 0) & ints <= 30]
ints[ints%%5 == 0 | ints%%6 == 0 & ints <= 30] #Different from above
```


### Problem 1
Use logical operators to simultaneously find the odd numbers between -50 and 0 (inclusive) and the even numbers between 0 and 50 (inclusive)

```{r}
ints <- -50:50
ints[(ints <= 0 & ints%%2 == 1) | (ints >= 0 & ints%%2 == 0)]
```



## Missing data and NA's
First, let's read a preiously saved image of the dataset from the previous lecture that we change into long format.

```{r}
rm(list=ls(all=TRUE)) #Always make your your environment is ready.

#Before reading the format, ask where in the directory you're in:
getwd()

#If not in the course's folder, set properly the working directory:
setwd("/home/oscar/Dropbox/R wizardry/2017/2017. Day 3")
getwd() #To make sure that the working directory was corectly set. Now, anything we save will go to the "2017. Day 3" folder.

#Let's see what's in this directory (or folder)
dir()

#Let's read the long-format "compounds" dataset we saved from last weeek, by reading the RDS files using the readRDS() function. If you didn't save this object, please go to D2L, under content > datsets, and download the file "Compounds_triplicates_long.csv" and read it into R using the read.csv() function. Pick one of the two options.

#In my case, as the data set is in a folder other than the working directory just set, I'll simply copy the full path to the dataset "Compounds dataset.csv" (reagarless of where I saved it!). This allows me to read the dataset without changing the working directory again:

#To read the RDS file
data <- readRDS("/home/oscar/Dropbox/R wizardry/2017/Compounds dataset.rds")

#To read the csv file from D2L
data <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")
  
str(data)
data$compound
unique(data$compound)

```


Once the data is imported, let's do some subsetting. 

We can use subset() to split the data based on some logical argument contained within the dataset. For example, let's only look at data from the first half of the experiment (before day 200)

```{r}
unique(data$day)

early_data <- subset(data, data$day < 200)
early_data

library(dplyr)
#install.packages("dplyr")

early_data2 <- data %>% filter(day < 200) %>% print()
unique(early_data$day)

```


NA represents an empty slot and are also produced when invalid math is attempted. In addition to TRUE and FALSE, NA is another type of logical variable

```{r}
###############################################################
#Ommiting column X from csv files
data
drops <- "X" #Name of the column we want to left out from the dataset. This "X" column is atuomatically created by the "write.csv()" function when the deafult argument "row.names = TRUE" is not set to "false".

data <- data[ , !(names(data) %in% drops)] # Find anycolumn called "X" and removes it
#Now the first column should be "compound"
##############################################################

class(NA)

as.numeric("a")
```


Unfortunately, we often have to deal with missing data so lets throw some in
```{r}
mean(data$methane)
head(data$methane)

```

Having NA messes up a lot of functions
```{r}
median(data [ , "methane_umoles"])
mean(data[ , 6])
```


Often there are built in ways to ignore them most common functions have a parameter such as na.rm, na.omit, na.exclude, etc...
```{r}
mean(data$day, na.rm = TRUE)
mean(data[ , 6], na.rm = TRUE)
```

But we can use logic to ignore them ourselves using is.na()
```{r}
cbind(data[1:10, 6], !is.na(data[1:10,6])) #Culumn-bind Returns 1 (TRUE) or 0 (FALSE)
data.frame(data[1:10, 6], !is.na(data[1:10,6])) #data.frame Returns TRUE or FALSE

```


### Problem 2:
Select the data from methane which is not NA and calculate its mean.

```{r}

data.frame(data[ , 6], !is.na(data[ ,6])) #Is it NOT NA?

data.frame(data[ ,5], is.na(data[ ,5])) #Is it NA?

#First we ask about NAs in column 5, then we subset data to use column 5. That's why column 5 is called twice in the code below
mean(data[!is.na(data[ ,6]), 6])

#Let's analyze the answer. The inner piece of code, takes all data that is not NA:
!is.na(data[ , 6]) #Let's call this part "inner code"

#The external part of the code, subsets the data to get all rows (conditioned as "no NAs" by the inner code), and column 6:
data["<inner code goes here>", 6]

#The most exterior code is simply the mean() functon.
mean()



#Another way to calculate the mean without using logic operators, is simply:
mean(data$methane_umoles, na.rm = TRUE)

```



## 1.3 Calculations based on another column

```{r}
colnames(data)
```


"tapply()" applys a function to one column based on the groups found in another column
```{r}
?tapply


#Methane based on salinity or group factors
tapply(data$methane_umoles, data$salinity, FUN = sd, na.rm = TRUE)

tapply(data$methane, data$group, FUN = sd, na.rm =TRUE)
```


Aggregate is the general form, allowing you to group by more than one column.

```{r}
aggregate(data$methane_umoles, list(data$compound, data$group), mean)

aggregate(data$methane_umoles, list(data$compound, data$group), mean)

#A disadvantage of "aggregate()" is that you have to rename the columns.

```


ALTERNATIVELY, this form keeps the names

```{r}
aggregate(methane_umoles ~ compound + group, data = data, FUN = mean, na.rm = TRUE)

```


A third way to use aggregate. Let's calculate the mean and standard deviation in the methane reads by day.

```{r}
head(data)

methane_mean_day <- aggregate(data$methane_umoles, 
                              by = list(data$compound,
                                        data$salinity,
                                        data$group,
                                        data$day),#data$Staff,
                                        
                              FUN = mean)

methane_mean_day

methane_sd_day <- aggregate(data$methane_umoles, 
                              by = list(data$compound,
                                        data$salinity,
                                        data$group,
                                        data$day), #data$Staff),
                                        FUN = sd)
methane_sd_day
```



### Problem 3

At this points there are two datasets that only differ in one column: one contains the mean and the other the standars deviation. Also, rename the columns with more addecuate names.

```{r}
#The easiest will be extract the column from one dataset (e.g. methane_day_sd$x) and add it to the other dataset (e.g. methane_day_mean):
data_stats <- cbind(methane_mean_day, methane_sd_day$x)
head(data_stats, 20)


colnames(data_stats) <- c("compound", "salinity", "group", "day", "mean_methane", "sd_methane")
head(data_stats, 15)

#Alternatively, add
methane_mean_day$sd <- methane_sd_day$x

methane_mean_day[ , 6] <- methane_sd_day$x #There was no warning about overwritting the methane_mean_day column. Be careful!


#Write the data_stats into csv file. Have it handy, we'll use it again.


```

Now, let's add a new column of NEW DATA to an existing dataset

```{r}

data_stats$Staff <- rep(c("Willy_Wonka", "Chuck_Norris"), length(data_stats$day )/2)

length(data$day)

str(data_stats)


getwd()
#write.csv(data_stats, "/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv", row.names = FALSE)

```


Let's say you wanted to quickly calculate your sample size for each categorical factor of compound and group. How would we do that in such a way that R is not counting the NAs?

There are three ways:

```{r}
aggregate(data, list(data$compound, data$group), function(x) (sum(!is.na(x))))

```


## 1.4 Brief intro to graphs using R base plotting functions
Although during the course we won't use the basic R plotting that much as we'll focus on the ggplot2 package, it's good to understand the very basics.


```{r}
plot(mean_methane ~ day, data = data_stats)
plot(data_stats$day, data_stats$mean_methane)
```


Here is a variety of ways to plot box-and-whisker plots in R

```{r}
?boxplot
boxplot(mean_methane ~ group, data = data_stats, col="steelblue", ylab = "Median Methane Formation", range=0, ylim = c(-20, 240))

boxplot(mean_methane ~ group, data = data_stats, col="steelblue", ylab="Median Methane Formation", range=1, ylim=c(-20, 240))

boxplot(mean_methane ~ group, data = data_stats, col="steelblue", ylab="Median Methane Formation", outline=FALSE, ylim=c(-20, 240), boxwex=0.25)
```


## 1.5 Create and export a summary table

```{r}


data_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/compounds_triplicates_long.csv")

ag <- aggregate(mean_methane ~ day + compound + group, data = data_stats, FUN = median, na.rm=TRUE)

ag
getwd() #Before saving a file, make sure where you're saving it. Change the location if necessary:
setwd("/home/oscar/Dropbox/R wizardry/2017")
dir()

```

... and warnings to it
```{r}

#Funtion to check if the name you want to use in your new dataset is already taken. This will prevent you from overwritting an existent object by mistake:

if(sum(dir() == "Methane medians.csv") > 0) {print("What are you doing?!!! File already exists :)")} 

#If we don't get a warning, it means there are no objects with the name "Methane medians.csv"

#Now, let's write a file with the name "Methane medians.csv"
#write.csv(ag, "Methane medians.csv", row.names = FALSE)


#Let's run the funtion again, see what happens:
if(sum(dir() == "Methane medians.csv") > 0) {print("Watch out, DUMMY!!! File already exists :)")} 

#As long as you have a file with the name "Methane medians.csv" in your set directory, you'll get the warning. If you delete the file from your folder, the warning won't show up anymore.
```


## 1.6 Selecting data based on another column

We have been selecting data based on itself. We can also select data based on other data.

We can find the odd letters
```{r}
?letters
letters[(1:26)%%2 == 1]

```

We can select the data collected on day 1
```{r}
#Reading the data
data_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")

str(data_stats)


data_stats[data_stats$day == 1, ]
```


We can select the data collected on day 1 and day 10
```{r}
data_stats[data_stats$day == 1 | data_stats$day == 10, ]


```


We can select based on 2 or more data types
```{r}
data_stats[data_stats$day == 1 & data_stats$compound == "unamended", ]
```


We can store this subsetted data into a new variable
```{r}
subdata <- data_stats[data_stats$day == 1 & data_stats$compound == "unamended", ] 

subdata$mean_methane

```


## 1.7 Finding data based on its value


```{r}
?which

data$day == 1

which(data_stats$day == 1) 
which(is.na(data_stats$day))

#Get the row number containing the highest methane read
which(data_stats$mean_methane == max(data_stats$mean_methane, na.rm = T))

#Get the entire info of row containing the highest methane read
data[which(data_stats$mean_methane == max(data_stats$mean_methane, na.rm = T)),]
```


## 1.8 Random numbers and selecting random data

```{r}
?runif #Random uniform
?rnorm
?rgamma
?rpois
?rnbinom
?rbinom
?sample

runif(10,min=0,max=1)
runif(10,0,1) < 0.4
rnorm(10,mean=1,sd=1)
sample(1:10,size=4)

#Set the seed to create reproducible simulations.
set.seed(666)
runif(10,0,10)

data_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")

data_stats$mean_methane[runif(length(data_stats$mean_methane), min=0, max=1) < 0.1] #Min and max are the lower and upper limits of the distribution

sample(data_stats$sd, size=10, replace=TRUE)

```


## 1.9 Strings

```{r}
rm(list=ls(all=TRUE))

data_stats <- read.csv("/home/oscar/Dropbox/R wizardry/2017/Datasets/compounds_triplicates_long.csv")

?substring()
?strsplit()
?paste()
?sub()
?gsub()
?grep()
?sapply()
?match()
?unique
```

### 1.9.1 Logical operators on strings
```{r}

?as.integer
?c
?"["
?letters

int <- 1:20
int[int<10]
char <- letters
letters[letters < "f"]
words <- c("1","hello","hello2", "my", "name", "is", "computer")
words <= "hello3"
# R is smart (sometimes), for logical operators it ranks character sequences alpha-numerically

```


### 1.9.2 Combining strings
```{r}

?paste


#Use the paste function to combine multiple vectors of character data into a single string
paste("a", "b", "c")

#Can change the seperation using the sep parameter
paste("a", "b", "c", sep = "-")
paste("a", "b", "c", sep = "")

data_stats$new.col <- paste(data_stats$salinity, data_stats$group, sep=" ")
head(data_stats)

# can combine multiple objects from a single vector into a single string
phrase <- c("Fish","Are","Friends")
nchar(phrase)
newphrase = paste(phrase,collapse=' ')
nchar(newphrase)
#Can combine any one-celled variable
paste(1,"1","&", "one")

#If you have multi-celled variables, you will create multiple strings
paste("replicate", 1:10, sep = ": ")
```


### 1.9.3 Seperating strings
```{r}

?substring
?nchar
?strsplit
?sub

#substring (aka substr) and strsplit can seperate strings

#substring grabs the characters between two points in the string
string <- paste(1,2,3,4,5,6,7,8,9, sep = "")
substring(string, first=1, last=3)
substr(string, start=1, stop=3)

substring(string,7,9)
substring(string,9,5)
substring(string,9,100) #The last element is "9"


#nchar tells you how long the string is
nchar(string)
substring(string, 5, nchar(string))

#strsplit seperates the string into fragments
#It makes breaks when it finds the string you want within the larger string
geno <- "TACAGATATCCGGA"
strsplit(geno, "TA")

#The string you are breaking on is not included in the output
getwd()
workingdir <- "/home/oscar/Dropbox/R wizardry/2017/2017. Week 4"
strsplit(workingdir, "/")

#strsplit puts its output inside of a list (since the arrays in the list can be of different sizes)
#We get pull the relevant vector/array out of a list using [[NUMBER]]
strsplit(workingdir, "/")[[1]]
strsplit(workingdir, "/")[[1]][4:8]


#We can use sapply if our list has multiple slots and each array is the same size
string <- c("G1:TACA", "G2:TTTA", "G3:ACCT")
sub(".*:", "", string)
sub(":","HAPPY",string)

#The ".*X" syntax is a regular expression that is recognizable to perl and other languages. It is matching the X argument after any given string, in this case it is matching on the 
#colon (:) and splitting the string and ignoring everything prior to the colon

sapply(strsplit(string, ":"), "[", 2)

# Try a value of 1, and a value of 2 here
sapply(strsplit(string, ":"), "[", 1)
# Why does the sapply function work??? Because the command "[" is a command to R to extract information specific to lists and the function 'strsplit' creates an object formatted as a list

sapply(strsplit(string, ":"), "[", 1) 

```

### 1.9.4 Managing strings

```{r}


?"[["
?substr
?substring

#TODO: Kyle, what is this code doing?
read.table(text = string, sep = ":", as.is = TRUE)$V2
substring(string, 4)
substring(string,3)
## ^^ Try different values instead of 4, such as 3, 5, 1, etc.

tes <- c("1gene.GATTACA","2gene.GTCATTA","3gene.ATTCGAA")
dat <- c(5,3,2)
h <- data.frame(tes,dat)

sapply(strsplit(as.character(h$tes), "\\."), "[", 1)
# ^^ Try different values for 1 above

nx <- c(Abc = 123, pi = pi)
nx[1] ; nx["pi"] # keeps names, whereas "[[" does not:
nx[[1]] ; nx[["pi"]]
```



### 1.9.5 Matching strings

```{r}
?match
?grep

words
words <- c("1","hello","hello2", "my", "name", "is", "computer")
match("hello",words)
grep("hello",words)

match("me",words)
grep("me",words)

words[grep("me",words)]
```


### 1.9.6 Partial matches and regular expressions

```{r}
?sample
?letters
?grep
?grepl
?paste
?regexpr
?strsplit
?unlist
```



Let's create a fake sequence of genomic data, 100,000 bp long each of the 4 bp A, C, G, and T have equal probability of being represented we want to sample from the letters a, c, g, and t, with replacement

```{r}
set.seed(1)
genome <- sample(c("g","a","c","t"),size=1e4,replace=TRUE,prob=c(1/4,1/4,1/4,1/4))

unique(genome)
```

this gives us the individual vector positions of the genome for each bp
```{r}
genome[10] # this is the 10th bp of the genomic sequence
```


let's collapse this down into a single character vector
```{r}
geneseq <- paste(genome, collapse='')
```

let's say that we are interested in finding out where/if a specific sequence occurs the sequence of interest is GATTACA

```{r}
gene <- "gattaca"
```


We can use regular expressions to find out where among the single character vector that R first returns a positive hit for GATTACA

```{r}
x <- regexpr(gene, geneseq)
x
```


Let's verify that this is indeed the bp in the genome corresponding to that return
```{r}
genome[x[1]:(x[1]+6)]
```


Let's then split the genomic sequence up around GATTACA (i.e., split the genomic sequence up and remove GATTACA). For each positive hit on GATTACA, it will split split the vector
```{r}
y <- unlist(strsplit(geneseq,gene)) #Divides original sequence into two vector, based on gattaca

length(y)-1 # This returns the number of matches for GATTACA in the genomic sequence

grepl(gene, geneseq) # is GATTACA in the original genomic sequence - this should return TRUE
```


does each remaining subsection of the genome contain GATTACA?
```{r}
grepl(gene,y) # this should return FALSE as we split the sequence on GATTACA's 
```


What if you were then interested in the pieces of the genome that contained an additional bp sequence of interest, such as AAACGGG?

```{r}
grep("aaacggg", y)
regexpr("aaacggg", y) # where does AAACGGG first occur?
```


Alternatively you could do this:
```{r}
nchar(geneseq)
nchar(y) 
genome <- genome[(x[1]+attr(x,"match.length")):length(genome)]
geneseq <- paste(genome,collapse='')
nchar(geneseq)
z <- regexpr(gene,geneseq)
genome[z[1]:(z[1]+attr(z,"match.length")-1)]
genome <- genome[(z[1]+attr(x,"match.length")):length(genome)]
geneseq <- paste(genome,collapse='')
nchar(geneseq)

#rinse and repeat to find all genomic locations that contain GATTACA bp sequence
```
